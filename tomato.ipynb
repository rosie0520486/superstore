{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODUmDR7q3oSYjTSOMwx1Be",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rosie0520486/superstore/blob/main/tomato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GSWD2W1htD5",
        "outputId": "216ce911-3995-4ce9-c0ad-84d01ec3d4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Collecting shimmy>=2.0\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n",
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 581  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 507           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.4610275e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.77         |\n",
            "|    explained_variance   | -1.67e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 3.86e+10      |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -1.05e-05     |\n",
            "|    value_loss           | 8.91e+10      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 482           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.1979137e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.77         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 3.02e+11      |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -9.61e-06     |\n",
            "|    value_loss           | 6.21e+11      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.043127e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.38e+11     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -2.95e-06    |\n",
            "|    value_loss           | 1.71e+12     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 445           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.5716068e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.77         |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.72e+12      |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -2.09e-06     |\n",
            "|    value_loss           | 3.35e+12      |\n",
            "-------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 435       |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 28        |\n",
            "|    total_timesteps      | 12288     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.73e+12  |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | -2.14e-06 |\n",
            "|    value_loss           | 5.46e+12  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 439       |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 32        |\n",
            "|    total_timesteps      | 14336     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.03e+12  |\n",
            "|    n_updates            | 60        |\n",
            "|    policy_gradient_loss | -1.15e-06 |\n",
            "|    value_loss           | 8.1e+12   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 442       |\n",
            "|    iterations           | 8         |\n",
            "|    time_elapsed         | 36        |\n",
            "|    total_timesteps      | 16384     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.69e+12  |\n",
            "|    n_updates            | 70        |\n",
            "|    policy_gradient_loss | -1.11e-06 |\n",
            "|    value_loss           | 1.13e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 440       |\n",
            "|    iterations           | 9         |\n",
            "|    time_elapsed         | 41        |\n",
            "|    total_timesteps      | 18432     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.35e+12  |\n",
            "|    n_updates            | 80        |\n",
            "|    policy_gradient_loss | -1.53e-06 |\n",
            "|    value_loss           | 1.5e+13   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 444       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 46        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.5e+12   |\n",
            "|    n_updates            | 90        |\n",
            "|    policy_gradient_loss | -2.17e-07 |\n",
            "|    value_loss           | 1.92e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 447       |\n",
            "|    iterations           | 11        |\n",
            "|    time_elapsed         | 50        |\n",
            "|    total_timesteps      | 22528     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.21e+13  |\n",
            "|    n_updates            | 100       |\n",
            "|    policy_gradient_loss | -2.14e-06 |\n",
            "|    value_loss           | 2.4e+13   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 443       |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 55        |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.48e+13  |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | -3.43e-07 |\n",
            "|    value_loss           | 2.92e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 445       |\n",
            "|    iterations           | 13        |\n",
            "|    time_elapsed         | 59        |\n",
            "|    total_timesteps      | 26624     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.76e+13  |\n",
            "|    n_updates            | 120       |\n",
            "|    policy_gradient_loss | -1.96e-07 |\n",
            "|    value_loss           | 3.49e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 444       |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 64        |\n",
            "|    total_timesteps      | 28672     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.11e+13  |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | -8.39e-08 |\n",
            "|    value_loss           | 4.13e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 445       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 68        |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.4e+13   |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -1.55e-06 |\n",
            "|    value_loss           | 4.83e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 447       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 73        |\n",
            "|    total_timesteps      | 32768     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.73e+13  |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -5.64e-07 |\n",
            "|    value_loss           | 5.58e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 445       |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 78        |\n",
            "|    total_timesteps      | 34816     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.16e+13  |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | -9.64e-08 |\n",
            "|    value_loss           | 6.34e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 445       |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 82        |\n",
            "|    total_timesteps      | 36864     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -3.58e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.6e+13   |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | -1.09e-06 |\n",
            "|    value_loss           | 7.17e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 446       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 87        |\n",
            "|    total_timesteps      | 38912     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 2.38e-07  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.02e+13  |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -5.16e-07 |\n",
            "|    value_loss           | 8.08e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 443       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 92        |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.51e+13  |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -6.92e-07 |\n",
            "|    value_loss           | 9.03e+13  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 444       |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 96        |\n",
            "|    total_timesteps      | 43008     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.98e+13  |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | -7.04e-07 |\n",
            "|    value_loss           | 1e+14     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 443       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 101       |\n",
            "|    total_timesteps      | 45056     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.47e+13  |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | -5.55e-07 |\n",
            "|    value_loss           | 1.1e+14   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 443       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 106       |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.95e+13  |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -7.77e-07 |\n",
            "|    value_loss           | 1.21e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 445       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 110       |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.65e+13  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -1.61e-07 |\n",
            "|    value_loss           | 1.33e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 443       |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 115       |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.24e+13  |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | -7.53e-07 |\n",
            "|    value_loss           | 1.45e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 443       |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 120       |\n",
            "|    total_timesteps      | 53248     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.89e+13  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | -8.34e-07 |\n",
            "|    value_loss           | 1.57e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 442       |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 124       |\n",
            "|    total_timesteps      | 55296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.63e+13  |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -3.19e-08 |\n",
            "|    value_loss           | 1.71e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 440       |\n",
            "|    iterations           | 28        |\n",
            "|    time_elapsed         | 130       |\n",
            "|    total_timesteps      | 57344     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.99e+13  |\n",
            "|    n_updates            | 270       |\n",
            "|    policy_gradient_loss | -1.79e-06 |\n",
            "|    value_loss           | 1.84e+14  |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 441      |\n",
            "|    iterations           | 29       |\n",
            "|    time_elapsed         | 134      |\n",
            "|    total_timesteps      | 59392    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -2.77    |\n",
            "|    explained_variance   | 0        |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 1e+14    |\n",
            "|    n_updates            | 280      |\n",
            "|    policy_gradient_loss | 3.65e-08 |\n",
            "|    value_loss           | 1.99e+14 |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 440       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 139       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.05e+14  |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | -6.07e-07 |\n",
            "|    value_loss           | 2.13e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 439       |\n",
            "|    iterations           | 31        |\n",
            "|    time_elapsed         | 144       |\n",
            "|    total_timesteps      | 63488     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.14e+14  |\n",
            "|    n_updates            | 300       |\n",
            "|    policy_gradient_loss | -6.91e-07 |\n",
            "|    value_loss           | 2.29e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 440       |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 148       |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.77     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.24e+14  |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | -5.93e-07 |\n",
            "|    value_loss           | 2.45e+14  |\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class TomatoGreenhouseEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # state variables [Internal Temperature, external, CO2, maturity, production cost, inventory]\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0, -10, 400, 0, 0, 0]),\n",
        "            high=np.array([40, 40, 2000, 100, np.inf, np.inf]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # defining agent actions [(0=weak,1=,2=medium,3=strong), Ventilation(0/1), harvest(0/1)]\n",
        "        self.action_space = spaces.MultiDiscrete([4,2,2])\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([20, 10, 400, 0, 0, 0])  #initialization\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        temp, ext_temp, co2, maturity, cost, stock = self.state\n",
        "        heating_level, ventilation, harvest = action\n",
        "\n",
        "        # gas heating\n",
        "        gas_consumption = [0, 1, 2, 3][heating_level]\n",
        "        cost += gas_consumption * 10  # 비용 계산\n",
        "\n",
        "        # CO2 control\n",
        "        temp += 0.5*(ext_temp - temp) + gas_consumption*1.0\n",
        "        co2 += gas_consumption*50 - ventilation*100\n",
        "\n",
        "        # maturity\n",
        "        maturity += max(0, (temp - 15)*0.5)\n",
        "\n",
        "        reward = 0\n",
        "        # harvest decision\n",
        "        if harvest and maturity >= 90:\n",
        "            harvested_amount = maturity * 0.5  # productivity calculation\n",
        "            stock += harvested_amount\n",
        "            reward += harvested_amount * 200  # revenue of sales\n",
        "            maturity = 0  #initialization\n",
        "\n",
        "        # reward から　費用マイナス\n",
        "        reward -= cost\n",
        "\n",
        "        # state update\n",
        "\n",
        "        self.state = np.array([temp, ext_temp, co2, maturity, cost, stock])\n",
        "\n",
        "        done = False\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "!pip install stable-baselines3\n",
        "!pip install gym\n",
        "!pip install 'shimmy>=2.0'\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# 이미 정의한 환경 클래스 불러오기\n",
        "class TomatoGreenhouseEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=np.array([0, -10, 400, 0, 0, 0]),\n",
        "            high=np.array([40, 40, 2000, 100, np.inf, np.inf]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        self.action_space = gym.spaces.MultiDiscrete([4,2,2])\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([20, 10, 400, 0, 0, 0])\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        temp, ext_temp, co2, maturity, cost, stock = self.state\n",
        "        heating_level, ventilation, harvest = action\n",
        "        gas_consumption = [0, 1, 2, 3][heating_level]\n",
        "        cost += gas_consumption * 10\n",
        "        temp += 0.5*(ext_temp - temp) + gas_consumption*1.0\n",
        "        co2 += gas_consumption*50 - ventilation*100\n",
        "        maturity += max(0, (temp - 15)*0.5)\n",
        "        reward = 0\n",
        "        if harvest and maturity >= 90:\n",
        "            harvested_amount = maturity * 0.5\n",
        "            stock += harvested_amount\n",
        "            reward += harvested_amount * 200\n",
        "            maturity = 0\n",
        "        reward -= cost\n",
        "        self.state = np.array([temp, ext_temp, co2, maturity, cost, stock])\n",
        "        done = False\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "# 환경 생성\n",
        "env = TomatoGreenhouseEnv()\n",
        "\n",
        "# PPO 에이전트 모델 생성\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "\n",
        "# 학습 수행 (100,000회 반복)\n",
        "model.learn(total_timesteps=100000)\n",
        "\n",
        "# 학습 모델 저장 (나중에 사용가능)\n",
        "model.save(\"tomato_greenhouse_agent\")\n",
        "\n",
        "# 저장된 모델 로드\n",
        "model = PPO.load(\"tomato_greenhouse_agent\")\n",
        "\n",
        "# 환경 초기화\n",
        "obs = env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "# 시뮬레이션 수행 (200단계 동안)\n",
        "for step in range(200):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    print(f\"Step:{step+1}, Action:{action}, State:{obs}, Reward:{reward}\")\n",
        "\n",
        "print(f\"Total Reward: {total_reward}\")"
      ]
    }
  ]
}